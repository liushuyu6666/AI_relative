{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gaussian_Regression.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"11orcRkGZDcUqCWoKZZHHdBh9lu6Qdn8y","authorship_tag":"ABX9TyNXQ379AEbJC/y25+1ML1Mr"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"scPqV-PkmR_P","colab_type":"text"},"source":["Introduction\n","--------------------\n","This homework is programming based, where you must use Python to explore the fitting and generalization of regression models via simulation.  \n","Suppose that $Y$ and $Y$ are both real valued random variables, where $X$ takes value in $(0, 1)$ and $Y$ depends on $X$ according to\n","\n",">$$Y = cos(2 \\pi X) + Z ..................... (1)$$  \n","\n","where $Z$ is a zero mean Gaussian random variable with variance $\\sigma$, and $Z$ is independent of $X$. But assume\n","that you do not know this dependency of $Y$ on $X$ and that you only observe a sample of $N (X, Y)$ pairs.\n","Based on the observed sample, you must learn a polynomial regression model and examine the fitting and\n","generalization capability of your model in relation to the model complexity and sample size.  \n","Below detailed instructions are given to guide you through this exercise. These instructions only serve as a guideline, which your implementation need not to rigorously follow. You must use Python to write your code. It is fine and encouraged, but NOT compulsory, if you use a Python package that does automatic differentiation. But you must implement manually gradient-based optimization. That is, the\n","use of the package is only for you to compute the required gradients and you must manually code up the update of model parameters. You need to submit the following deliverables.  \n","* All Python code\n","* A concise report explaining your findings."]},{"cell_type":"code","metadata":{"id":"e5IKmbe2k_2q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1600487903881,"user_tz":240,"elapsed":4719,"user":{"displayName":"shuyu liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf-UwUZB4YXwmGHBIgiFBJ8IFzBw2jqdBSvC_0=s64","userId":"00742976267113831789"}},"outputId":"4086fcfd-f97f-478d-b6e8-9805479c690d"},"source":["import torch\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"KgJRJf4hkJFu","colab_type":"text"},"source":["We need DCG_node to check all attributes"]},{"cell_type":"code","metadata":{"id":"IqtZ-RsNkIdb","colab_type":"code","colab":{}},"source":["def DCG_node(listValue):\n","    for (i, v) in enumerate(listValue):\n","        print(f\"{i}.data: {v.data}\\n{i}.requires_grad: {v.requires_grad}\\n{i}.grad: {v.grad}\\n{i}.grad_fn: {v.grad_fn}\\n{i}.is_leaf: {v.is_leaf}\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZPuTP9iHl1xM","colab_type":"text"},"source":["getData\n","---------------------------\n","Write a function **getData** that generates a dataset ${(x_i, y_i) : i = 1, 2, ... N}$ g of $N (X, Y)$ pairs for a given value of $N$ and $\\sigma$. The $X$ values are drawn uniformly at random from $(0, 1)$ and the corresponding $Y$ values are generated according to (1).  \n","The dataset created by **getData** will then be used to fit your regression models. Of course, in the design of your regression model, you should assume no knowledge on how the dataset is generated.  \n","The regression models we consider will be exclusively polynomial models, namely, predicts $Y$ from $X$ according to\n","$$Y = a_0 + a_1X + a_2X^2 + ... + a_dX^d$$\n","where $d$ is the polynomial degree and $a_i$'s are coefficients to be estimated."]},{"cell_type":"code","metadata":{"id":"I-XURDfXlycw","colab_type":"code","colab":{}},"source":["def getData(N: int, sigma: float, plot = False):\n","    X = torch.empty(N,).uniform_(0, 1).type(torch.FloatTensor)\n","    f = torch.cos(2 * np.pi * X)\n","    Z = torch.normal(0, sigma ** 2, size=(N,))\n","    Y = f + Z\n","    if plot:\n","        fig, ax = plt.subplots()\n","        sns.lineplot(x=X, y=f, color='red', label = 'f(x)', ax=ax)\n","        sns.scatterplot(x=X, y=Y, color='blue', label='training data', ax=ax);\n","        plt.title(\"getData\")\n","    return [(xi, yi) for (xi, yi) in zip(X, Y)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1klQCeC6nya","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600488968234,"user_tz":240,"elapsed":298,"user":{"displayName":"shuyu liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf-UwUZB4YXwmGHBIgiFBJ8IFzBw2jqdBSvC_0=s64","userId":"00742976267113831789"}},"outputId":"9af7c31d-e6f2-4189-e9aa-7233fa9ebec3"},"source":["np.shape(getData(500, 1))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(500, 2)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"hXzI8Qfv7YMW","colab_type":"text"},"source":["getMSE\n","---------------------------------\n","Write a function **getMSE** which computes the mean square error (MSE) for a given dataset fitted to a specified polynomial."]},{"cell_type":"code","metadata":{"id":"JkEKN_lHh04T","colab_type":"code","colab":{}},"source":["# MSE = (1/N) sum ((Y - (1, x, x ^ 2, ... x ^ d) * A) ^ 2)\n","# A.size() = (d + 1, 1)\n","# x.size() = (N, 1)\n","# Y_real.size() = (N, 1)\n","def getMSE(Y_real, x, A):\n","    d = A.size()[0] - 1\n","    N = x.size()[0]\n","    X = torch.cat(([(x ** i).view(N, 1) for i in range(d+1)]), dim=1)\n","    Y_pred = torch.matmul(X, A)\n","    return (1 / N) * torch.sum((Y_real - Y_pred) ** 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tneba1-n7iyY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1600490629145,"user_tz":240,"elapsed":478,"user":{"displayName":"shuyu liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghf-UwUZB4YXwmGHBIgiFBJ8IFzBw2jqdBSvC_0=s64","userId":"00742976267113831789"}},"outputId":"a27bc23a-37a6-4fd8-8f0f-4fed59279867"},"source":["x = torch.FloatTensor([0, 1, 2, 3])\n","Y_real = torch.FloatTensor([0, 2, 4, 9])\n","A = torch.tensor([1.0, 0, 1.0], requires_grad=True)\n","L = getMSE(Y_real, x, A)\n","L.backward()\n","print(DCG_node([Y_real, x, A, L]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.data: tensor([0., 2., 4., 9.])\n","0.requires_grad: False\n","0.grad: None\n","0.grad_fn: None\n","0.is_leaf: True\n","\n","1.data: tensor([0., 1., 2., 3.])\n","1.requires_grad: False\n","1.grad: None\n","1.grad_fn: None\n","1.is_leaf: True\n","\n","2.data: tensor([1., 0., 1.])\n","2.requires_grad: True\n","2.grad: tensor([1.5000, 2.5000, 6.5000])\n","2.grad_fn: None\n","2.is_leaf: True\n","\n","3.data: 0.75\n","3.requires_grad: True\n","3.grad: None\n","3.grad_fn: <MulBackward0 object at 0x7f3e84f855c0>\n","3.is_leaf: False\n","\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"lu3KgbGPl3cH","colab_type":"text"},"source":["push to github"]}]}